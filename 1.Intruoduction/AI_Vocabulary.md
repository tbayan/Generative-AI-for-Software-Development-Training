//hand-picked words by my first impressions.

LLM - large language model, a generative AI system that generates text mainly based on user prompts, based on probability.
tokens - minimum parts of the part of llm assessment system, based on those tokens, analysing them and acting as a minimum unit, to help generate the texts, contents.
pipelines - a structure or methods to use for LLM development ( no sol)
transformers - a new algorithmic innovation way, help the AI grow and become more precise.
model - a certain LLM model that will be trained
training- feeding the data to a LLM model to make it more related or achieve certain results labelling - using human knowledge, for some specified area or topics, like health-related or other parts, to improve the accuracy of the data.
reasoning - methods of thinking? I hear it a lot, the main backbones of a llm systems
hallucinations - when the llm or some AI system is not following the prompt, this happens? 

